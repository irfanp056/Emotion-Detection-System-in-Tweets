{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Emotion Detection System in Tweets\n\nwe are going to study the [Brazilian Stock Market Tweets with Emotions\n](https://www.kaggle.com/datasets/fernandojvdasilva/stock-tweets-ptbr-emotions) dataset to identify the emotions in Brazilian stock market tweets. ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"data\"></a>\n\n---\n# Data Exploration\n\n\nIn this section, we are going to load the files into `pandas.DataFrame`. At last, elaborate our preprocessed datasets.\n","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install scikit-learn==1.0.2\n\n# download the portuguese spacy module\n!pip install spacy==2.3.7\n!python -m spacy download pt_core_news_sm-2.3.0 --direct","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:36:10.933062Z","iopub.execute_input":"2023-09-26T17:36:10.933523Z","iopub.status.idle":"2023-09-26T17:36:46.706749Z","shell.execute_reply.started":"2023-09-26T17:36:10.933486Z","shell.execute_reply":"2023-09-26T17:36:46.705004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:46.710709Z","iopub.execute_input":"2023-09-26T17:36:46.711348Z","iopub.status.idle":"2023-09-26T17:36:46.718957Z","shell.execute_reply.started":"2023-09-26T17:36:46.711284Z","shell.execute_reply":"2023-09-26T17:36:46.717375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:36:46.720764Z","iopub.execute_input":"2023-09-26T17:36:46.721168Z","iopub.status.idle":"2023-09-26T17:36:46.736017Z","shell.execute_reply.started":"2023-09-26T17:36:46.721129Z","shell.execute_reply":"2023-09-26T17:36:46.734663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = pd.read_csv('/kaggle/input/stock-tweets-ptbr-emotions/tweets_stocks.csv')\ntest_set  = pd.read_csv('/kaggle/input/stock-tweets-ptbr-emotions/tweets_stocks-full_agreement.csv')\n\ntrain_set","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:46.737828Z","iopub.execute_input":"2023-09-26T17:36:46.738292Z","iopub.status.idle":"2023-09-26T17:36:46.805497Z","shell.execute_reply.started":"2023-09-26T17:36:46.738249Z","shell.execute_reply":"2023-09-26T17:36:46.804182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clean train-set\n\nLet's create the train set, excluding the test data and non-useful classes.","metadata":{}},{"cell_type":"code","source":"# remove test set from train set\nmask_remove_test = np.logical_not(train_set['tweet_id'].isin(test_set['tweet_id']))\ntrain_set = train_set[mask_remove_test]\n\ntrain_set","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:46.811570Z","iopub.execute_input":"2023-09-26T17:36:46.812016Z","iopub.status.idle":"2023-09-26T17:36:46.846869Z","shell.execute_reply.started":"2023-09-26T17:36:46.811980Z","shell.execute_reply":"2023-09-26T17:36:46.845663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are there any test data in train set?\ntrain_set[train_set['tweet_id'].isin(test_set['tweet_id'])]","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:46.848496Z","iopub.execute_input":"2023-09-26T17:36:46.848967Z","iopub.status.idle":"2023-09-26T17:36:46.867938Z","shell.execute_reply.started":"2023-09-26T17:36:46.848917Z","shell.execute_reply":"2023-09-26T17:36:46.865621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's transform the cases without class in `NEUTRAL`.","metadata":{}},{"cell_type":"code","source":"# columns of interest\nX_column = 'text'\nY_columns = ['TRU','DIS','JOY','SAD','ANT','SUR','ANG','FEA','NEUTRAL']","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:46.869744Z","iopub.execute_input":"2023-09-26T17:36:46.870183Z","iopub.status.idle":"2023-09-26T17:36:46.877284Z","shell.execute_reply.started":"2023-09-26T17:36:46.870147Z","shell.execute_reply":"2023-09-26T17:36:46.875779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ignore cases without class\ndd = train_set.query('NEUTRAL == -1')\nfor idx, row in dd.iterrows():\n    for column in Y_columns:\n        train_set.at[idx, column] = 0\n    train_set.at[idx, 'NEUTRAL'] = 1\n\ntrain_set","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:46.879539Z","iopub.execute_input":"2023-09-26T17:36:46.880796Z","iopub.status.idle":"2023-09-26T17:36:47.343973Z","shell.execute_reply.started":"2023-09-26T17:36:46.880711Z","shell.execute_reply":"2023-09-26T17:36:47.342659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# are there any train data without class?\ntrain_set.query('NEUTRAL == -1')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:47.345737Z","iopub.execute_input":"2023-09-26T17:36:47.346404Z","iopub.status.idle":"2023-09-26T17:36:47.364514Z","shell.execute_reply.started":"2023-09-26T17:36:47.346309Z","shell.execute_reply":"2023-09-26T17:36:47.362180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"class\"></a>\n\n---\n# Multilabel Classification\n\nMultilabel classification is a classification task where each sample is labeled with `m` labels from `n_classes` possible classes, where `m` can be `0` to `n_classes` inclusive. [sklearn - Multilabel classification](https://scikit-learn.org/stable/modules/multiclass.html#multilabel-classification)\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"strategy1\"></a>\n\n## Strategy 1 - TF-IDF\n\n- First, we are going to create a simple text preprocessor\n- Next, we are going to use the TF-IDF to extract features from the preprocessed texts\n- At last, we are going to use Decision Tree algorithm to predict the classes\n","metadata":{}},{"cell_type":"code","source":"import re\nimport string\nimport pt_core_news_sm\nfrom unidecode import unidecode\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nnlp = pt_core_news_sm.load()","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:47.365930Z","iopub.execute_input":"2023-09-26T17:36:47.366310Z","iopub.status.idle":"2023-09-26T17:36:51.256848Z","shell.execute_reply.started":"2023-09-26T17:36:47.366276Z","shell.execute_reply":"2023-09-26T17:36:51.255498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleTextPreprocessor(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Text preprocessing includes steps:\n        - Lower case\n        - Remove accents\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, *_):\n        data = pd.Series(X) if not isinstance(X, pd.Series) else X\n        data = data.apply(self._preprocess_text)\n        return data\n\n    def _preprocess_text(self, text):\n        # handed functions\n        pre_text = text.lower()\n        pre_text = unidecode(pre_text)\n        return pre_text","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:51.259086Z","iopub.execute_input":"2023-09-26T17:36:51.259684Z","iopub.status.idle":"2023-09-26T17:36:51.274358Z","shell.execute_reply.started":"2023-09-26T17:36:51.259624Z","shell.execute_reply":"2023-09-26T17:36:51.272010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just a test to see the preprocessing\ntp = SimpleTextPreprocessor()\ntp.transform(train_set['text'].iloc[0:4])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:51.277032Z","iopub.execute_input":"2023-09-26T17:36:51.277491Z","iopub.status.idle":"2023-09-26T17:36:51.295039Z","shell.execute_reply.started":"2023-09-26T17:36:51.277450Z","shell.execute_reply":"2023-09-26T17:36:51.293546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\n\npipe1 = Pipeline(steps=[\n    ('normalize', SimpleTextPreprocessor()), \n    ('features', TfidfVectorizer(\n        ngram_range=(1, 2), analyzer='word',\n        sublinear_tf=True, max_features=3_000,\n        max_df=0.9, preprocessor=None\n    )),\n    ('classifier', DecisionTreeClassifier(random_state=1))\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:51.297029Z","iopub.execute_input":"2023-09-26T17:36:51.297513Z","iopub.status.idle":"2023-09-26T17:36:51.310786Z","shell.execute_reply.started":"2023-09-26T17:36:51.297472Z","shell.execute_reply":"2023-09-26T17:36:51.309277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npipe1.fit(train_set[X_column], train_set[Y_columns])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:51.317102Z","iopub.execute_input":"2023-09-26T17:36:51.317643Z","iopub.status.idle":"2023-09-26T17:36:55.956498Z","shell.execute_reply.started":"2023-09-26T17:36:51.317587Z","shell.execute_reply":"2023-09-26T17:36:55.955029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation\n\nLet's evaluate the classes performance using `classification_report`. The reported averages include macro average (averaging the unweighted mean per label), weighted average (averaging the support-weighted mean per label), and sample average (only for multilabel classification). Micro average (averaging the total true positives, false negatives and false positives) is only shown for multi-label or multi-class with a subset of classes, because it corresponds to accuracy otherwise and would be the same for all metrics. [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:36:55.958264Z","iopub.execute_input":"2023-09-26T17:36:55.959030Z","iopub.status.idle":"2023-09-26T17:36:55.965923Z","shell.execute_reply.started":"2023-09-26T17:36:55.958977Z","shell.execute_reply":"2023-09-26T17:36:55.964436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import multilabel_confusion_matrix\n\ndef print_confusion_matrix(confusion_matrix, axes, class_label, class_names, fontsize=12):\n    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names,)\n    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes, cmap=\"crest\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    axes.set_ylabel('True label')\n    axes.set_xlabel('Predicted')\n    axes.set_title(class_label)\n\ndef run_confusion_matrix(Y_test, Y_pred, labels, size=(3,3)):\n    vis_arr = multilabel_confusion_matrix(Y_test, Y_pred)\n    fig, ax = plt.subplots(size[0], size[1], figsize=(12, 7))\n    for axes, cfs_matrix, label in zip(ax.flatten(), vis_arr, labels):\n        print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n    \n    fig.tight_layout()\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-26T17:36:55.968029Z","iopub.execute_input":"2023-09-26T17:36:55.968639Z","iopub.status.idle":"2023-09-26T17:36:55.981993Z","shell.execute_reply.started":"2023-09-26T17:36:55.968553Z","shell.execute_reply":"2023-09-26T17:36:55.980567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:55.983770Z","iopub.execute_input":"2023-09-26T17:36:55.984178Z","iopub.status.idle":"2023-09-26T17:36:55.995909Z","shell.execute_reply.started":"2023-09-26T17:36:55.984135Z","shell.execute_reply":"2023-09-26T17:36:55.994684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict the classes\nY_test = test_set[Y_columns]\nY_pred = pipe1.predict(test_set[X_column])\n\nprint(classification_report(Y_test, Y_pred, target_names=Y_columns))\nprint('accuracy', f'{accuracy_score(Y_test, Y_pred):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:55.997695Z","iopub.execute_input":"2023-09-26T17:36:55.998048Z","iopub.status.idle":"2023-09-26T17:36:56.053576Z","shell.execute_reply.started":"2023-09-26T17:36:55.998015Z","shell.execute_reply":"2023-09-26T17:36:56.052716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_confusion_matrix(Y_test, Y_pred, labels=Y_columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:56.054709Z","iopub.execute_input":"2023-09-26T17:36:56.055519Z","iopub.status.idle":"2023-09-26T17:36:58.256693Z","shell.execute_reply.started":"2023-09-26T17:36:56.055481Z","shell.execute_reply":"2023-09-26T17:36:58.255251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"strategy2\"></a>\n\n## Strategy 2 - TF-IDF + Robust Preprocessing\n\nNow, we are going to execute a serie of preprocessing techniques to better clean our data.\n","metadata":{}},{"cell_type":"code","source":"class RobustTextPreprocessor(SimpleTextPreprocessor):\n    \"\"\"\n    Text preprocessing includes steps:\n        - Lower case\n        - Remove accents\n        - Replace @citations (it didn't performe well)\n        - Replace http://websites.com (it didn't performe well)\n        - Remove numbers\n        - Remove special characters symbols\n        - Remove breakline\n        - Lemming\n    \"\"\"\n    def __init__(self, nlp=nlp):\n        self.nlp = nlp\n\n    def _preprocess_text(self, text):\n        # handed functions\n        pre_text = super()._preprocess_text(text)\n        pre_text = self._replace_citation(pre_text)\n        pre_text = self._replace_website(pre_text)\n        pre_text = self._remove_number(pre_text)\n        pre_text = self._remove_punct(pre_text)\n        pre_text = self._remove_breakline(pre_text)\n        pre_text = self._remove_extra_spaces(pre_text)\n        pre_text = self._lemmatize(pre_text)\n        return pre_text\n\n    def _remove_number(self, text):\n        # Remove numbers\n        return re.sub(r'\\d', ' ', text)\n\n    def _replace_citation(self, text):\n        # Replace @\\w by CITATION\n        return re.sub(r'@[\\w\\d]+', 'CITATION',  text)\n\n    def _replace_website(self, text):\n        # Replace http://websites.com by SITE\n        return re.sub(r'https?:\\/\\/.+', 'SITE',  text)\n\n    def _remove_punct(self, text):\n        # Replace special characters symbols\n        spaces = ' '*len(string.punctuation)\n        return text.translate(str.maketrans(string.punctuation, spaces))\n\n    def _remove_breakline(self, text):\n        # Remove breakline\n        return re.sub(r'\\n', ' ',  text)\n        \n    def _remove_extra_spaces(self, text):\n        # Remove extra spaces\n        return re.sub(' +', ' ', text)\n\n    def _lemmatize(self, text):\n        # Normalization\n        doc = self.nlp(text)\n        return ' '.join(t.lemma_ for t in doc)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:58.258143Z","iopub.execute_input":"2023-09-26T17:36:58.258930Z","iopub.status.idle":"2023-09-26T17:36:58.272233Z","shell.execute_reply.started":"2023-09-26T17:36:58.258887Z","shell.execute_reply":"2023-09-26T17:36:58.270916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just a test to see the preprocessing\ntp = RobustTextPreprocessor()\ntp.transform(train_set['text'].iloc[0:4])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:58.274177Z","iopub.execute_input":"2023-09-26T17:36:58.275259Z","iopub.status.idle":"2023-09-26T17:36:58.329017Z","shell.execute_reply.started":"2023-09-26T17:36:58.275218Z","shell.execute_reply":"2023-09-26T17:36:58.328155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipe2 = Pipeline(steps=[\n    ('normalize', RobustTextPreprocessor()), \n    ('features', TfidfVectorizer(\n        ngram_range=(1, 2), analyzer='word',\n        sublinear_tf=True, max_features=3_000,\n        max_df=0.9, preprocessor=None\n    )),\n    ('classifier', DecisionTreeClassifier(random_state=1))\n])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:58.330366Z","iopub.execute_input":"2023-09-26T17:36:58.331140Z","iopub.status.idle":"2023-09-26T17:36:58.336668Z","shell.execute_reply.started":"2023-09-26T17:36:58.331075Z","shell.execute_reply":"2023-09-26T17:36:58.335775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npipe2.fit(train_set[X_column], train_set[Y_columns])","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:36:58.337963Z","iopub.execute_input":"2023-09-26T17:36:58.338526Z","iopub.status.idle":"2023-09-26T17:37:37.887000Z","shell.execute_reply.started":"2023-09-26T17:36:58.338491Z","shell.execute_reply":"2023-09-26T17:37:37.885657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"# predict the classes\nY_test = test_set[Y_columns].to_numpy()\nY_pred = pipe2.predict(test_set[X_column])\n\nprint(classification_report(Y_test, Y_pred, target_names=Y_columns))\nprint('accuracy', f'{accuracy_score(Y_test, Y_pred):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:37:37.888642Z","iopub.execute_input":"2023-09-26T17:37:37.889603Z","iopub.status.idle":"2023-09-26T17:37:40.696379Z","shell.execute_reply.started":"2023-09-26T17:37:37.889549Z","shell.execute_reply":"2023-09-26T17:37:40.695146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_confusion_matrix(Y_test, Y_pred, labels=Y_columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T17:37:40.697843Z","iopub.execute_input":"2023-09-26T17:37:40.698230Z","iopub.status.idle":"2023-09-26T17:37:42.652340Z","shell.execute_reply.started":"2023-09-26T17:37:40.698195Z","shell.execute_reply":"2023-09-26T17:37:42.650996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"conclusion\"></a>\n\n---\n# Conclusion\n\nIn general, both techniques presented similar results. In this case, the robust preprocessing approach was not able to help the classifier. 😔   \nAnyway, we was able to create an algorithm capable of predicting nine different emotions for a stock market tweet.\n","metadata":{}}]}